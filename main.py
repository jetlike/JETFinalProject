# main.py
import time
import cv2
from pathlib import Path

# â† now that face/ is a package, import from it
from face.facial_recog     import FaceRecognitionSystem
from audio.listener        import WakeWordListener
from vision.hand_tracker   import get_pointing_target
from llm.query_engine      import QueryEngine


# adjust this path to wherever your .ppn lives:
KEYWORD_MODEL = Path(__file__).parent / "models" / "hey_bot.ppn"

def authenticate_user(system: FaceRecognitionSystem, timeout: float = 30.0):
    """
    Open the camera and keep grabbing frames until someone
    registered is recognized, or until timeout. Returns the name.
    """
    cap = cv2.VideoCapture(0)
    start = time.time()
    print("ğŸ‘¤ Please position yourself in front of the cameraâ€¦")
    while True:
        if time.time() - start > timeout:
            cap.release()
            raise RuntimeError("Authentication timed out")
        ret, frame = cap.read()
        if not ret:
            continue
        name = system.recognize_once(frame)
        if name not in ("Unknown", "NoFace"):
            cap.release()
            print(f"âœ… Authenticated as {name}")
            return name
        # you can show the frame for feedback if you like:
        cv2.putText(frame, "Authenticatingâ€¦", (10,30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)
        cv2.imshow("Auth", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    cap.release()
    cv2.destroyAllWindows()
    raise RuntimeError("Authentication aborted")

def main():
    # â€”â€”â€” 1. Face-based authentication â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    face_sys = FaceRecognitionSystem()
    user = authenticate_user(face_sys)

    # â€”â€”â€” 2. Spin up the LLM engine â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    engine = QueryEngine(model="gpt-3.5-turbo", temperature=0.3)

    # â€”â€”â€” 3. Define what happens on wake-word â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    def on_wake():
        print("\nğŸ”” Wake word detected!")
        wav = listener._record_with_threshold()   # record question
        print(f"ğŸ“ Saved query to {wav}")
        # transcribe
        transcript = listener.transcriber.transcribe(wav)
        print(f"ğŸ’¬ You said: {transcript}")
        # vision
        obj = get_pointing_target()
        print(f"ğŸ‘† Pointed at: {obj}")
        # query LLM
        answer = engine.answer(question=transcript, context_text=f"User pointed at {obj}")
        print(f"ğŸ¤– Bot: {answer}\n")

    # â€”â€”â€” 4. Start wake-word listener â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    listener = WakeWordListener(
        keyword_paths=[str(KEYWORD_MODEL)],
        sensitivities=[0.6],
        callback=on_wake
    )
    listener.start()
    print(f"\nSystem is live for {user}. Say your wake-word nowâ€¦ (Ctrl+C to quit)\n")

    try:
        while True:
            time.sleep(0.1)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Shutting downâ€¦")
    finally:
        listener.stop()

if __name__ == "__main__":
    main()
